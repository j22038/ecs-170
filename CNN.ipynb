{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75779f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import cv2\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9505326",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Needs work\n",
    "#referenced - https://medium.com/@myringoleMLGOD/simple-convolutional-neural-network-cnn-for-dummies-in-pytorch-a-step-by-step-guide-6f4109f6df80\n",
    "#\t          - https://medium.com/@kritiikaaa/convolution-neural-networks-guide-for-your-first-cnn-project-7ea56f7f6960\n",
    "# Formal dataset definition\n",
    "from google.colab import drive\n",
    "drive.mou\n",
    "\n",
    "!ls -l '/content/drive/MyDrive/ECS_170/data/processed/merged_data'\n",
    "\n",
    "class PlantHealthDataset(Dataset):\n",
    "\tdef __init__(self, root_dir):\n",
    "\t\tself.samples = []\n",
    "\t\tself.transform = transforms.Compose([\n",
    "\t\t\t\t\ttransforms.ToTensor(),\n",
    "\t\t])\n",
    "\n",
    "\t\tfor plant_type in os.listdir(root_dir):\n",
    "\t\t\tplant_path = os.path.join(root_dir, plant_type)\n",
    "\t\t\tif not os.path.isdir(plant_path):\n",
    "\t\t\t\tcontinue\n",
    "\n",
    "\t\t\tfor split in [\"train\", \"valid\"]:\n",
    "\t\t\t\tsplit_path = os.path.join(plant_path, split)\n",
    "\t\t\t\tif not os.path.isdir(split_path):\n",
    "\t\t\t\t\tcontinue\n",
    "\n",
    "\t\t\t\tfor condition in os.listdir(split_path):\n",
    "\t\t\t\t\t# Conditions for example healthy, bacterial spot etc.\n",
    "\t\t\t\t\tcondition_path = os.path.join(split_path, condition)\n",
    "\t\t\t\t\tif not os.path.isdir(condition_path):\n",
    "\t\t\t\t\t\tcontinue\n",
    "\n",
    "\t\t\t\t\t# For now, we only care about if it's healthy (0) or not (1)\n",
    "\t\t\t\t\tlabel = 0 if \"healthy\" in condition.lower() else 1\n",
    "\n",
    "\t\t\t\t\tfor fname in os.listdir(condition_path):\n",
    "\t\t\t\t\t\tif fname.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "\n",
    "\t\t\t\t\t\t\t# Add each image path + label to the samples\n",
    "\t\t\t\t\t\t\tself.samples.append((\n",
    "\t\t\t\t\t\t\t\t\t\tos.path.join(condition_path, fname),\n",
    "\t\t\t\t\t\t\t\t\t\tlabel\n",
    "\t\t\t\t\t\t\t))\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\treturn len(self.samples)\n",
    "\n",
    "\tdef __getitem__(self, idx):\n",
    "\t\timg_path, label = self.samples[idx]\n",
    "\t\timage = Image.open(img_path).convert(\"L\") # Open as grayscale\n",
    "\t\timage = self.transform(image)\n",
    "\t\treturn image, torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "\n",
    "#CNN definition\n",
    "class plantCNN(nn.Module):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(plantCNN, self).__init__()\n",
    "\t\tself.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)\n",
    "\t\tself.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "\t\tself.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "\n",
    "\t\tself.pool = nn.MaxPool2d(2, 2)\n",
    "\t\tself.relu = nn.ReLU()\n",
    "\t\tself.flatten = nn.Flatten()\n",
    "\n",
    "\t\t# After 3 pools: 128 -> 64 -> 32 -> 16\n",
    "\t\tself.fc1 = nn.Linear(64 * 16 * 16, 128)\n",
    "\t\tself.fc2 = nn.Linear(128, 2)  # Healthy vs Diseased\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tx = self.pool(self.relu(self.conv1(x)))\n",
    "\t\tx = self.pool(self.relu(self.conv2(x)))\n",
    "\t\tx = self.pool(self.relu(self.conv3(x)))\n",
    "\t\tx = self.flatten(x)\n",
    "\t\tx = self.relu(self.fc1(x))\n",
    "\t\tx = self.fc2(x)\n",
    "\t\treturn x\n",
    "\n",
    "# Load the dataset\n",
    "data_root = \"/content/drive/MyDrive/ECS_170 (Dataset)/processed/PlantDiseasesDataset\"\n",
    "dataset = PlantHealthDataset(data_root)\n",
    "\n",
    "split_idx = int(0.8 * len(dataset))\n",
    "train_data, val_data = torch.utils.data.random_split(dataset, [split_idx, len(dataset) - split_idx])\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=64, shuffle=False)\n",
    "\n",
    "# Set up training\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = plantCNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training and validation loops\n",
    "def train_epoch(model, loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "    for imgs, labels in tqdm(loader, desc=\"Training\"):\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (preds == labels).sum().item()\n",
    "    acc = 100 * correct / total\n",
    "    return running_loss / len(loader), acc\n",
    "\n",
    "def eval_epoch(model, loader, criterion):\n",
    "    model.eval()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in tqdm(loader, desc=\"Validation\"):\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (preds == labels).sum().item()\n",
    "    acc = 100 * correct / total\n",
    "    return running_loss / len(loader), acc\n",
    "\n",
    "epochs = 17\n",
    "for epoch in range(epochs):\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, optimizer, criterion)\n",
    "    val_loss, val_acc = eval_epoch(model, val_loader, criterion)\n",
    "    print(f\"\\nEpoch [{epoch+1}/{epochs}]\")\n",
    "    print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n",
    "    print(f\"Val Loss:   {val_loss:.4f} | Val Acc:   {val_acc:.2f}%\\n\")\n",
    "\n",
    "os.makedirs(\"/content/drive/MyDrive/ECS_170/models\", exist_ok=True)\n",
    "torch.save(model.state_dict(), \"/content/drive/MyDrive/ECS_170/models/plant_health_cnn.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
