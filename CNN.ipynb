{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75779f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import cv2\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9505326",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Needs work\n",
    "#referenced - https://medium.com/@myringoleMLGOD/simple-convolutional-neural-network-cnn-for-dummies-in-pytorch-a-step-by-step-guide-6f4109f6df80\n",
    "#\t          - https://medium.com/@kritiikaaa/convolution-neural-networks-guide-for-your-first-cnn-project-7ea56f7f6960\n",
    "# Formal dataset definition\n",
    "\n",
    "# !ls -l '/content/drive/MyDrive/ECS_170/data/processed/merged_data'\n",
    "\n",
    "#Add thing\n",
    "\n",
    "#CNN definition\n",
    "class plantCNN(nn.Module):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(plantCNN, self).__init__()\n",
    "\t\tself.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)\n",
    "\t\tself.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "\t\tself.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "\n",
    "\t\tself.pool = nn.MaxPool2d(2, 2)\n",
    "\t\tself.relu = nn.ReLU()\n",
    "\t\tself.flatten = nn.Flatten()\n",
    "\n",
    "\t\tself.fc1 = nn.Linear(64 * 8 * 8, 128)\n",
    "\t\tself.fc2 = nn.Linear(128, 10) #Healthy, Bacterial spot, Early blight, Late blight, Leaf Mold, Mosaic virus, Septoria leaf spot, Spider mites, Target Spot, Yellow Leaf Curl Virus\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tx = self.pool(self.relu(self.conv1(x)))\n",
    "\t\tx = self.pool(self.relu(self.conv2(x)))\n",
    "\t\tx = self.pool(self.relu(self.conv3(x)))\n",
    "\t\tx = self.flatten(x)\n",
    "\t\tx = self.relu(self.fc1(x))\n",
    "\t\tx = self.fc2(x)\n",
    "\t\treturn x\n",
    "\n",
    "# Load the dataset\n",
    "data_root = \"/content/drive/MyDrive/ECS_170/Tomato_Dataset_Splitted_V2\"\n",
    "\n",
    "transform = transforms.Compose([\n",
    "     transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_data = dataset.ImageFolder(os.path.join(data_root, \"train\"), transform)\n",
    "val_data = dataset.ImageFolder(os.path.join(data_root, \"val\"), transform)\n",
    "test_data = dataset.ImageFolder(os.path.join(data_root, \"test\"), transform)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(val_data, batch_size=64, shuffle=False)\n",
    "\n",
    "# Set up training\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = plantCNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training and validation loops\n",
    "def train_epoch(model, loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "    for imgs, labels in tqdm(loader, desc=\"Training\"):\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (preds == labels).sum().item()\n",
    "    acc = 100 * correct / total\n",
    "    return running_loss / len(loader), acc\n",
    "\n",
    "def eval_epoch(model, loader, criterion):\n",
    "    model.eval()\n",
    "    # store labels and predictions\n",
    "    labels_array = []\n",
    "    preds_array = []\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in tqdm(loader, desc=\"Validation\"):\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            labels_array.append(labels.cpu().numpy())\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            preds_array.append(preds.cpu().numpy())\n",
    "            total += labels.size(0)\n",
    "            correct += (preds == labels).sum().item()\n",
    "    acc = 100 * correct / total\n",
    "    y_actual = np.concatenate(labels_array)\n",
    "    y_predicted = np.concatenate(preds_array)\n",
    "    return running_loss / len(loader), acc, y_actual, y_predicted\n",
    "\n",
    "epochs = 17\n",
    "patience = 5\n",
    "threshold = 0.1\n",
    "best_val_loss = 1\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, optimizer, criterion)\n",
    "    val_loss, val_acc, y_actual, y_predicted = eval_epoch(model, val_loader, criterion)\n",
    "    print(f\"\\nEpoch [{epoch+1}/{epochs}]\")\n",
    "    print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n",
    "    print(f\"Val Loss:   {val_loss:.4f} | Val Acc:   {val_acc:.2f}%\\n\")\n",
    "    print(confusion_matrix(y_actual, y_predicted))\n",
    "    print(classification_report(y_actual, y_predicted))\n",
    "    # early stopping\n",
    "    patience_count = 0\n",
    "\n",
    "    if(best_val_loss >= val_loss):\n",
    "        bset_val_loss = val_loss\n",
    "\n",
    "    if(val_loss > best_val_loss - threshold):\n",
    "        patience_count += 1\n",
    "    else:\n",
    "        patience_count = 0\n",
    "\n",
    "    if(patience_count > patience):\n",
    "        break\n",
    "\n",
    "os.makedirs(\"/content/drive/MyDrive/ECS_170/models\", exist_ok=True)\n",
    "torch.save(model.state_dict(), \"/content/drive/MyDrive/ECS_170/models/plant_health_cnn.pth\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
